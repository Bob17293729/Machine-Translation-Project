{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fXdXe_OiCdWu"
      },
      "outputs": [],
      "source": [
        "#!python -m pip install --upgrade pip\n",
        "#!python -m pip install torchtext==0.6.0\n",
        "#!python -m pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3mxEZx8NBCS1"
      },
      "outputs": [],
      "source": [
        "#!python -m pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4hOubTntBJhG"
      },
      "outputs": [],
      "source": [
        "#!python -m spacy download en_core_web_sm\n",
        "#!python -m spacy download zh_core_web_sm\n",
        "#!python -m spacy download de_core_news_sm"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load dataset from the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oVjBGHWz0OKz"
      },
      "outputs": [],
      "source": [
        "from torchtext.data import Field\n",
        "from torch.utils.data import Dataset, random_split\n",
        "import json\n",
        "from einops import rearrange\n",
        "\n",
        "max_dataset_size = 440000\n",
        "train_set_size = 400000\n",
        "valid_set_size = 40000\n",
        "\n",
        "max_input_length = 128\n",
        "max_target_length = 128\n",
        "EPOCH = 20 \n",
        "\n",
        "SRC = Field(tokenize = \"spacy\",\n",
        "            tokenizer_language=\"zh_core_web_sm\",\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True,\n",
        "            batch_first=True)\n",
        "\n",
        "TRG = Field(tokenize = \"spacy\",\n",
        "            tokenizer_language=\"en_core_web_sm\",\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True,\n",
        "            batch_first=True)\n",
        "\n",
        "\n",
        "zh_words_set, en_words_set = [[]], [[]]\n",
        "\n",
        "class TRANS(Dataset):\n",
        "    def __init__(self, data_file):\n",
        "        self.en_data, self.zh_data = self.load_data(data_file)\n",
        "    \n",
        "    def load_data(self, data_file):\n",
        "        en_data, zh_data = [], []\n",
        "        with open(data_file, 'rt', encoding='utf-8') as f:\n",
        "            for idx, line in enumerate(f): \n",
        "                if idx >= max_dataset_size: #We limit the dataset we use\n",
        "                    break\n",
        "                sample = json.loads(line.strip()) #Sample: dict()\n",
        "\n",
        "                en_data.append(TRG.tokenize(sample['english']))\n",
        "\n",
        "                zh_data.append(SRC.tokenize(sample['chinese']))\n",
        "\n",
        "        return en_data, zh_data #A dict(idx): EN, ZH\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.en_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.en_data[idx], self.zh_data[idx]\n",
        "\n",
        "data = TRANS('data/translation2019zh_train.json')\n",
        "train_data, valid_data = random_split(data, [train_set_size, valid_set_size])\n",
        "test_data = TRANS('data/translation2019zh_valid.json')\n",
        "\n",
        "SRC.build_vocab(data.zh_data, min_freq=20)\n",
        "TRG.build_vocab(data.en_data, min_freq=20)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Demo the vocab results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', '<sos>', '<eos>', '的', '，', '。', '在', '了', '是', '和', '、', '一', '我', '中', '他', '对', '你', '有', '一个', '“', '不', '”', '我们', '与', '：', '上', '为', '会', '这', '将', '也', '（', '）', '他们', '人', '可以', '说', '就', '个', '都', '被', '到', '而', '研究', '能', '进行', '并', '它', '从']\n",
            "638\n"
          ]
        }
      ],
      "source": [
        "# Printing a list of tokens mapping integer to strings\n",
        "print(SRC.vocab.itos[:50])\n",
        "# Printing a dict mapping tokens to indices\n",
        "#print(TRG.vocab.stoi)\n",
        "# Printing the index of an actual word\n",
        "print(SRC.vocab.stoi['游戏'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22602\n",
            "21797\n"
          ]
        }
      ],
      "source": [
        "print(len(SRC.vocab))\n",
        "print(len(TRG.vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4aYGQRq70OLC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pad index: 1\n",
            "sos index: 2\n",
            "eos index: 3\n",
            "unk index: 0\n"
          ]
        }
      ],
      "source": [
        "# Checking index of special tokens\n",
        "import torch.nn as nn\n",
        "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
        "SOS_IDX = TRG.vocab.stoi['<sos>']\n",
        "EOS_IDX = TRG.vocab.stoi['<eos>']\n",
        "UNK_IDX = TRG.vocab.stoi['<unk>']\n",
        "print('pad index:', PAD_IDX)\n",
        "print('sos index:', SOS_IDX)\n",
        "print('eos index:', EOS_IDX)\n",
        "print('unk index:', UNK_IDX)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "#torch.cuda.empty_cache() #清空缓存\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "\n",
        "def collote_fn(batch_samples):\n",
        "    en_batch, zh_batch = zip(*batch_samples)\n",
        "    zh_batch = SRC.process(zh_batch) #Pad, then convert to tensor\n",
        "    en_batch = TRG.process(en_batch)\n",
        "    \n",
        "    #Then we need to transpose: [B, seq] -> [seq, B]\n",
        "    return en_batch.transpose(0,1), zh_batch.transpose(0,1)\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collote_fn)\n",
        "valid_dataloader = DataLoader(valid_data, batch_size=32, shuffle=False, collate_fn=collote_fn)\n",
        "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False, collate_fn=collote_fn)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Consturcting the model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "P1L2qQrk0OK-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Anaconda\\envs\\DDA4220\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 1,699,800 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import get_scheduler\n",
        "from torch.optim import AdamW\n",
        "import math\n",
        "\n",
        "###足够大的值，使其不同次数运行的模型大小相同\n",
        "INPUT_DIM = 23500\n",
        "OUTPUT_DIM = 23000\n",
        "\n",
        "ENC_EMB_DIM = 16\n",
        "ATTN_DIM = 4\n",
        "DROPOUT = 0.2\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.src_embedding = nn.Embedding(INPUT_DIM, ENC_EMB_DIM)\n",
        "        self.tgt_embedding = nn.Embedding(INPUT_DIM, ENC_EMB_DIM)\n",
        "        self.transformer = nn.Transformer(nhead=ATTN_DIM, num_encoder_layers=2, d_model=ENC_EMB_DIM, dropout=DROPOUT)\n",
        "        self.linear = nn.Linear(ENC_EMB_DIM, OUTPUT_DIM)\n",
        "        pos_dropout = 0.1\n",
        "        max_seq_length = 128\n",
        "        self.pos_enc = PositionalEncoding(ENC_EMB_DIM, pos_dropout, max_seq_length)\n",
        "    \n",
        "    def forward(self, src, tgt, teacher_forcing_ratio=0.7, src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None, tgt_mask=None):\n",
        "        # TODO: Investigate masks, positional encoding, understand Rearrange(), debug model output (output has negative numbers for some reason)\n",
        "        # Original src shape: (sentence length=24?, batch_size=128)\n",
        "        # Original tgt shape: (sentence length=24?, batch_size=128)\n",
        "        # Transformer expects: (sentence length=24, batch_size=128, embedding_size=128)\n",
        "\n",
        "        src_emb = self.pos_enc(self.src_embedding(src) * math.sqrt(ENC_EMB_DIM))\n",
        "        tgt_emb = self.pos_enc(self.tgt_embedding(tgt) * math.sqrt(ENC_EMB_DIM))\n",
        "        out = self.transformer(src_emb, tgt_emb, tgt_mask=tgt_mask, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "model = TransformerModel().to(device)\n",
        "for p in model.parameters(): #Initialize the parameters\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_normal_(p)\n",
        "\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-3) \n",
        "scheduler = get_scheduler( \n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=len(train_dataloader)//10,\n",
        "    num_training_steps=EPOCH*len(train_dataloader),\n",
        ")\n",
        "\n",
        "\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "P7FKKikF0OLF"
      },
      "source": [
        "## Training and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dE8O8EKjV7Iw"
      },
      "outputs": [],
      "source": [
        "def gen_nopeek_mask(length):\n",
        "    mask = rearrange(torch.triu(torch.ones(length, length)) == 1, 'h w -> w h') #[Seq_length-1, Seq_length-1], generate triangle mask\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0)) #Fill we certain value\n",
        "    return mask\n",
        "\n",
        "\n",
        "def indices_to_string(LANGUAGE, batch): #string -> idx\n",
        "    words_list = []\n",
        "    for sentence in batch.transpose(1, 0):\n",
        "        sentence_list = sentence.tolist()\n",
        "        words = []\n",
        "        for index in sentence_list:\n",
        "            word = LANGUAGE.vocab.itos[index]\n",
        "            words.append(word)\n",
        "        words_list.append(words)\n",
        "    return words_list\n",
        "\n",
        "def string_to_indices(LANGUAGE, sentence): #idx -> string\n",
        "    if (LANGUAGE==TRG): #English\n",
        "        words = sentence.split()\n",
        "    else: #Chinese\n",
        "        words = LANGUAGE.tokenize(sentence)\n",
        "    indices = []\n",
        "    for word in words:\n",
        "        if word in LANGUAGE.vocab.stoi:\n",
        "            index = LANGUAGE.vocab.stoi[word]\n",
        "            indices.append(index)\n",
        "        else:\n",
        "            index = LANGUAGE.vocab.stoi['<unk>']\n",
        "            indices.append(index)\n",
        "    result = torch.tensor(indices)\n",
        "    return result\n",
        "\n",
        "def save_json(predicted_words,tgt_words,src_words): #将结果输出为json\n",
        "    print('saving predicted results...')\n",
        "    results = []\n",
        "    for source, pred, label in zip(src_words, predicted_words, tgt_words):\n",
        "        results.append({\n",
        "            \"sentence\": source, \n",
        "            \"prediction\": pred, \n",
        "            \"translation\": label[0]\n",
        "        })\n",
        "    with open('test_data_pred.json', 'wt', encoding='utf-8') as f:\n",
        "        for exapmle_result in results:\n",
        "            f.write(json.dumps(exapmle_result, ensure_ascii=False) + '\\n')\n",
        "\n",
        "def inference(model, example_sentence_src):\n",
        "    # Translate example sentence\n",
        "    example_tensor_src = string_to_indices(SRC, example_sentence_src).view(-1, 1) #[Sentence_length, Batch]\n",
        "    example_sentence_tgt = '<sos>' #Start index\n",
        "    example_tensor_tgt = string_to_indices(TRG, example_sentence_tgt).view(-1, 1) #Also convert to [Sentence_length, Batch]\n",
        "    src = example_tensor_src.to(device)\n",
        "    tgt = example_tensor_tgt.to(device)\n",
        "\n",
        "    for i in range(128): #Max length of generated sentece: 128\n",
        "        ###Below is similar to the Transforemer model\n",
        "        src_key_padding_mask = src == PAD_IDX\n",
        "        tgt_key_padding_mask = tgt == PAD_IDX\n",
        "        memory_key_padding_mask = src_key_padding_mask.clone()\n",
        "        src_key_padding_mask = rearrange(src_key_padding_mask, 'n s -> s n')\n",
        "        tgt_key_padding_mask = rearrange(tgt_key_padding_mask, 'n s -> s n')\n",
        "        memory_key_padding_mask = rearrange(memory_key_padding_mask, 'n s -> s n')\n",
        "        tgt_mask = gen_nopeek_mask(tgt.shape[0]).to(device)\n",
        "\n",
        "        output = model(src, tgt, 0, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask, tgt_mask=tgt_mask) #turn off teacher forcing\n",
        "\n",
        "        output_index = torch.argmax(output, dim=2)[-1].item() #得到输出后，在vocab维度上求argmax（找到可能性最大的单词idx)\n",
        "        if (output_index==4 and example_sentence_tgt[-2]==','): #多个逗号\n",
        "            break\n",
        "        output_word = TRG.vocab.itos[output_index] #idx -> string\n",
        "        example_sentence_tgt = example_sentence_tgt + ' ' + output_word #Concatenate\n",
        "        example_tensor_tgt = string_to_indices(TRG, example_sentence_tgt).view(-1, 1) #重新转换为#[Sentence_length, Batch]的tensor 作为target\n",
        "        tgt = example_tensor_tgt.to(device)\n",
        "        if output_word == '<eos>':\n",
        "            break\n",
        "    return example_sentence_tgt\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining training and testing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====Epoch 0=====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 0.000000:   0%|          | 0/12500 [00:00<?, ?it/s]d:\\Anaconda\\envs\\DDA4220\\lib\\site-packages\\torch\\nn\\functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "[TRAIN] loss: 5.809503: 100%|██████████| 12500/12500 [07:58<00:00, 26.14it/s]\n",
            "[VAL] loss: 7.901631: 100%|██████████| 1250/1250 [00:20<00:00, 61.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 5.810 | Train PPL: 333.453\n",
            "\t Val. Loss: 7.902 |  Val. PPL: 2701.685\n",
            "saving new weights...\n",
            "\n",
            "<sos> The <unk> is a <unk> of the <unk> . <eos>\n",
            "<sos> You ? <eos>\n",
            "=====Epoch 1=====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TRAIN] loss: 5.212811: 100%|██████████| 12500/12500 [08:11<00:00, 25.44it/s]\n",
            "[VAL] loss: 7.749830: 100%|██████████| 1250/1250 [00:20<00:00, 60.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 5.213 | Train PPL: 183.610\n",
            "\t Val. Loss: 7.750 |  Val. PPL: 2321.179\n",
            "saving new weights...\n",
            "\n",
            "<sos> The <unk> is not not not to be used to be used . <eos>\n",
            "<sos> <unk> : I ? <eos>\n",
            "=====Epoch 2=====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TRAIN] loss: 5.109494: 100%|██████████| 12500/12500 [08:16<00:00, 25.18it/s]\n",
            "[VAL] loss: 7.755970: 100%|██████████| 1250/1250 [00:20<00:00, 60.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 5.109 | Train PPL: 165.586\n",
            "\t Val. Loss: 7.756 |  Val. PPL: 2335.473\n",
            "saving new weights...\n",
            "\n",
            "<sos> The <unk> is not a good to be used . <eos>\n",
            "<sos> <unk> : You ? How ? <eos>\n",
            "=====Epoch 3=====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TRAIN] loss: 5.046818: 100%|██████████| 12500/12500 [08:15<00:00, 25.21it/s]\n",
            "[VAL] loss: 7.705946: 100%|██████████| 1250/1250 [00:20<00:00, 60.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 5.047 | Train PPL: 155.527\n",
            "\t Val. Loss: 7.706 |  Val. PPL: 2221.518\n",
            "saving new weights...\n",
            "\n",
            "<sos> <unk> , the <unk> can be not not not not not not not not not not not not . <eos>\n",
            "<sos> What is you ? <eos>\n",
            "=====Epoch 4=====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TRAIN] loss: 5.004351: 100%|██████████| 12500/12500 [08:13<00:00, 25.35it/s]\n",
            "[VAL] loss: 7.688020: 100%|██████████| 1250/1250 [00:20<00:00, 60.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 5.004 | Train PPL: 149.060\n",
            "\t Val. Loss: 7.688 |  Val. PPL: 2182.050\n",
            "saving new weights...\n",
            "\n",
            "<sos> The <unk> is not easy to be used to be not to be not to be not to be <unk> . <eos>\n",
            "<sos> What is you ? Are you ? <eos>\n",
            "=====Epoch 5=====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TRAIN] loss: 4.974838: 100%|██████████| 12500/12500 [08:17<00:00, 25.10it/s]\n",
            "[VAL] loss: 7.693235: 100%|██████████| 1250/1250 [00:20<00:00, 60.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 4.975 | Train PPL: 144.725\n",
            "\t Val. Loss: 7.693 |  Val. PPL: 2193.458\n",
            "saving new weights...\n",
            "\n",
            "<sos> So , the <unk> can be used to be used to be used . <eos>\n",
            "<sos> Yes , I love ? <eos>\n",
            "=====Epoch 6=====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TRAIN] loss: 4.952798: 100%|██████████| 12500/12500 [08:13<00:00, 25.33it/s]\n",
            "[VAL] loss: 7.645921: 100%|██████████| 1250/1250 [00:20<00:00, 60.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 4.953 | Train PPL: 141.571\n",
            "\t Val. Loss: 7.646 |  Val. PPL: 2092.095\n",
            "saving new weights...\n",
            "\n",
            "<sos> The <unk> is not easy to be used to be used . <eos>\n",
            "<sos> What is I ? <eos>\n",
            "=====Epoch 7=====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TRAIN] loss: 4.935265: 100%|██████████| 12500/12500 [08:13<00:00, 25.33it/s]\n",
            "[VAL] loss: 7.660564: 100%|██████████| 1250/1250 [00:20<00:00, 60.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 4.935 | Train PPL: 139.110\n",
            "\t Val. Loss: 7.661 |  Val. PPL: 2122.954\n",
            "saving new weights...\n",
            "\n",
            "<sos> The <unk> is not easy to be used to be <unk> . <eos>\n",
            "<sos> Yes ? I ? I ? I ? I ? <eos>\n",
            "=====Epoch 8=====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TRAIN] loss: 4.919694: 100%|██████████| 12500/12500 [08:14<00:00, 25.27it/s]\n",
            "[VAL] loss: 7.690053: 100%|██████████| 1250/1250 [00:20<00:00, 60.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 4.920 | Train PPL: 136.961\n",
            "\t Val. Loss: 7.690 |  Val. PPL: 2186.489\n",
            "saving new weights...\n",
            "\n",
            "<sos> The <unk> is not a <unk> . <eos>\n",
            "<sos> <unk> : Yes ? <unk> ? <eos>\n",
            "=====Epoch 9=====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TRAIN] loss: 4.905723: 100%|██████████| 12500/12500 [08:24<00:00, 24.80it/s]\n",
            "[VAL] loss: 7.642820: 100%|██████████| 1250/1250 [00:20<00:00, 59.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 4.906 | Train PPL: 135.060\n",
            "\t Val. Loss: 7.643 |  Val. PPL: 2085.616\n",
            "saving new weights...\n",
            "\n",
            "<sos> The <unk> is not a <unk> . <eos>\n",
            "<sos> <unk> : Yes ? <unk> ? <eos>\n",
            "=====Epoch 10=====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TRAIN] loss: 4.893079: 100%|██████████| 12500/12500 [08:15<00:00, 25.25it/s]\n",
            "[VAL] loss: 7.694813: 100%|██████████| 1250/1250 [00:20<00:00, 60.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 4.893 | Train PPL: 133.364\n",
            "\t Val. Loss: 7.695 |  Val. PPL: 2196.923\n",
            "saving new weights...\n",
            "\n",
            "<sos> The <unk> is not easy to be <unk> . <eos>\n",
            "<sos> Yes , I love ? Yes ? What ? <eos>\n",
            "=====Epoch 11=====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TRAIN] loss: 4.881420: 100%|██████████| 12500/12500 [08:22<00:00, 24.88it/s]\n",
            "[VAL] loss: 7.733724: 100%|██████████| 1250/1250 [00:20<00:00, 59.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 4.881 | Train PPL: 131.818\n",
            "\t Val. Loss: 7.734 |  Val. PPL: 2284.092\n",
            "saving new weights...\n",
            "\n",
            "<sos> <unk> , the <unk> can be <unk> . <eos>\n",
            "<sos> Yes , I ? <unk> ? <eos>\n",
            "=====Epoch 12=====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TRAIN] loss: 4.843423:   2%|▏         | 215/12500 [00:08<08:04, 25.35it/s]"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 127\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCH):\n\u001b[0;32m    126\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m=====Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m=====\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 127\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, train_dataloader, optimizer, criterion, CLIP)\n\u001b[0;32m    128\u001b[0m     val_loss \u001b[39m=\u001b[39m test(model, valid_dataloader, criterion)\n\u001b[0;32m    130\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mTrain Loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | Train PPL: \u001b[39m\u001b[39m{\u001b[39;00mmath\u001b[39m.\u001b[39mexp(train_loss)\u001b[39m:\u001b[39;00m\u001b[39m7.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[12], line 47\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, optimizer, criterion, clip)\u001b[0m\n\u001b[0;32m     45\u001b[0m tgt_key_padding_mask \u001b[39m=\u001b[39m tgt_key_padding_mask[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     46\u001b[0m tgt_mask \u001b[39m=\u001b[39m gen_nopeek_mask(tgt_inp\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 47\u001b[0m output \u001b[39m=\u001b[39m model(src, tgt_inp, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask, tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask, memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask)\n\u001b[0;32m     48\u001b[0m \u001b[39m#output: [seq_length, batch_size, vocab_size]\u001b[39;00m\n\u001b[0;32m     49\u001b[0m from_one_hot \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(output, dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m) \n",
            "File \u001b[1;32md:\\Anaconda\\envs\\DDA4220\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[1;32mIn[10], line 52\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[1;34m(self, src, tgt, teacher_forcing_ratio, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_mask)\u001b[0m\n\u001b[0;32m     50\u001b[0m src_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_enc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_embedding(src) \u001b[39m*\u001b[39m math\u001b[39m.\u001b[39msqrt(ENC_EMB_DIM))\n\u001b[0;32m     51\u001b[0m tgt_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_enc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtgt_embedding(tgt) \u001b[39m*\u001b[39m math\u001b[39m.\u001b[39msqrt(ENC_EMB_DIM))\n\u001b[1;32m---> 52\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(src_emb, tgt_emb, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask, tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask, memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask)\n\u001b[0;32m     53\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(out)\n\u001b[0;32m     54\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
            "File \u001b[1;32md:\\Anaconda\\envs\\DDA4220\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32md:\\Anaconda\\envs\\DDA4220\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:145\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m src\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model \u001b[39mor\u001b[39;00m tgt\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model:\n\u001b[0;32m    143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 145\u001b[0m memory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(src, mask\u001b[39m=\u001b[39;49msrc_mask, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask)\n\u001b[0;32m    146\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(tgt, memory, tgt_mask\u001b[39m=\u001b[39mtgt_mask, memory_mask\u001b[39m=\u001b[39mmemory_mask,\n\u001b[0;32m    147\u001b[0m                       tgt_key_padding_mask\u001b[39m=\u001b[39mtgt_key_padding_mask,\n\u001b[0;32m    148\u001b[0m                       memory_key_padding_mask\u001b[39m=\u001b[39mmemory_key_padding_mask)\n\u001b[0;32m    149\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
            "File \u001b[1;32md:\\Anaconda\\envs\\DDA4220\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32md:\\Anaconda\\envs\\DDA4220\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:315\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_causal \u001b[39m=\u001b[39m make_causal\n\u001b[0;32m    314\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> 315\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, is_causal\u001b[39m=\u001b[39;49mis_causal, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[0;32m    317\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    318\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m)\n",
            "File \u001b[1;32md:\\Anaconda\\envs\\DDA4220\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32md:\\Anaconda\\envs\\DDA4220\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:591\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    589\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x))\n\u001b[0;32m    590\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[39m=\u001b[39;49mis_causal))\n\u001b[0;32m    592\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[0;32m    594\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
            "File \u001b[1;32md:\\Anaconda\\envs\\DDA4220\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:599\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[1;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor,\n\u001b[0;32m    598\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 599\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, x,\n\u001b[0;32m    600\u001b[0m                        attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m    601\u001b[0m                        key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[0;32m    602\u001b[0m                        need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, is_causal\u001b[39m=\u001b[39;49mis_causal)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    603\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
            "File \u001b[1;32md:\\Anaconda\\envs\\DDA4220\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32md:\\Anaconda\\envs\\DDA4220\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1205\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1191\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1192\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[0;32m   1193\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1202\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   1203\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[0;32m   1204\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1205\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[0;32m   1206\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[0;32m   1207\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[0;32m   1208\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[0;32m   1209\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m   1210\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[0;32m   1211\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[0;32m   1212\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[0;32m   1213\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m   1214\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[0;32m   1215\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[0;32m   1216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[0;32m   1217\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
            "File \u001b[1;32md:\\Anaconda\\envs\\DDA4220\\lib\\site-packages\\torch\\nn\\functional.py:5376\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   5373\u001b[0m attn_output \u001b[39m=\u001b[39m scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n\u001b[0;32m   5374\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m-> 5376\u001b[0m attn_output \u001b[39m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n\u001b[0;32m   5377\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mview(tgt_len, bsz, attn_output\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m))\n\u001b[0;32m   5378\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_batched:\n\u001b[0;32m   5379\u001b[0m     \u001b[39m# squeeze the output if input was unbatched\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import math\n",
        "from tqdm.auto import tqdm\n",
        "import evaluate\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "\n",
        "train_loss_list, val_loss_list = [],[]\n",
        "\n",
        "def train(model: nn.Module,\n",
        "          dataloader: DataLoader,\n",
        "          optimizer: optim.Optimizer,\n",
        "          criterion: nn.Module,\n",
        "          clip: float):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    progress_bar = tqdm(range(len(dataloader))) #进度条\n",
        "    progress_bar.set_description(f'loss: {0:>7f}')\n",
        "\n",
        "    for batch_idx, (tgt, src) in enumerate(dataloader):\n",
        "\n",
        "        src = src.to(device) #ZH\n",
        "        tgt = tgt.to(device) #EN\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Original src shape: (sentence length=24, batch_size=16)\n",
        "        # Transformer expects: (sentence length=24, batch_size=16, embedding_size=128)\n",
        "        src_key_padding_mask = src == PAD_IDX\n",
        "        tgt_key_padding_mask = tgt == PAD_IDX\n",
        "        memory_key_padding_mask = src_key_padding_mask.clone()\n",
        "        src_key_padding_mask = rearrange(src_key_padding_mask, 'n s -> s n') #[batch_size, seq_length]\n",
        "        t = rearrange(tgt_key_padding_mask, 'n s -> s n')\n",
        "        memory_key_padding_mask = rearrange(memory_key_padding_mask, 'n s -> s n')\n",
        "        tgt_sentence_len = tgt.shape[0] - torch.sum(tgt_key_padding_mask, axis=1)\n",
        "        tgt_inp, tgt_out = tgt[:-1, :], tgt[1:, :]\n",
        "        tgt_key_padding_mask = tgt_key_padding_mask[:, :-1]\n",
        "        tgt_mask = gen_nopeek_mask(tgt_inp.shape[0]).to(device)\n",
        "\n",
        "        output = model(src, tgt_inp, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask, tgt_mask=tgt_mask)\n",
        "\n",
        "        #from_one_hot = torch.argmax(output, dim=2) \n",
        "        output = output.view(-1, output.shape[-1]) #[seq_length*batch_size, vocab_size]\n",
        "        tgt_out = tgt_out.contiguous().view(-1) #[seq_length*batch_size]\n",
        "\n",
        "        loss = criterion(output, tgt_out)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        progress_bar.set_description(f'[TRAIN] loss: {epoch_loss/(batch_idx+1):>7f}')\n",
        "        progress_bar.update(1) #更新进度条\n",
        "\n",
        "    train_loss_list.append(epoch_loss / len(dataloader)) #记录当前epoch的loss\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "\n",
        "def test(model: nn.Module,\n",
        "             dataloader: DataLoader,\n",
        "             criterion: nn.Module):\n",
        "\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    progress_bar = tqdm(range(len(dataloader))) #进度条\n",
        "    progress_bar.set_description(f'loss: {0:>7f}')\n",
        "\n",
        "    predicted_words, tgt_words, src_words = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (tgt, src) in enumerate(dataloader):\n",
        "\n",
        "            src = src.to(device) #ZH\n",
        "            tgt = tgt.to(device) #EN\n",
        "\n",
        "            src_key_padding_mask = src == PAD_IDX\n",
        "            tgt_key_padding_mask = tgt == PAD_IDX\n",
        "            memory_key_padding_mask = src_key_padding_mask.clone()\n",
        "            src_key_padding_mask = rearrange(src_key_padding_mask, 'n s -> s n')\n",
        "            tgt_key_padding_mask = rearrange(tgt_key_padding_mask, 'n s -> s n')\n",
        "            memory_key_padding_mask = rearrange(memory_key_padding_mask, 'n s -> s n')\n",
        "            tgt_mask = gen_nopeek_mask(tgt.shape[0]).to(device)\n",
        "            output = model(src, tgt, 0, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask, tgt_mask=tgt_mask) #turn off teacher forcing\n",
        "            #output: [seq_length, batch_size, vocab_size]\n",
        "            from_one_hot = torch.argmax(output, dim=2) #[seq_length, batch_size]\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "\n",
        "            tgt = tgt[1:].contiguous().view(-1)\n",
        "            loss = criterion(output, tgt)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            progress_bar.set_description(f'[VAL] loss: {epoch_loss/(batch_idx+1):>7f}')\n",
        "            progress_bar.update(1) #更新进度条\n",
        "    val_loss_list.append(epoch_loss / len(dataloader)) #记录当前epoch的loss\n",
        "    return epoch_loss / len(dataloader)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train and validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "CLIP = 0.5\n",
        "\n",
        "best_valid_loss = float('inf') #以loss 作为更新的指标\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "\n",
        "    print(f\"=====Epoch {epoch}=====\")\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
        "    val_loss = test(model, valid_dataloader, criterion)\n",
        "\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. PPL: {math.exp(val_loss):7.3f}')\n",
        "\n",
        "    if val_loss<best_valid_loss: #储存更好的模型\n",
        "        best_valid_loss = val_loss\n",
        "        print('saving new weights...\\n')\n",
        "        torch.save(model.state_dict(), f'epoch_{epoch+1}_valid_loss_{best_valid_loss:0.2f}_model_weights.bin')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YUFxU6DX6gR"
      },
      "outputs": [],
      "source": [
        "model_file = \"epoch_7_valid_loss_7.64_model_weights.bin\" #Mutable\n",
        "model.load_state_dict(torch.load(model_file)) #Loading storage parameter\n",
        "inference(model, \"你好嘛？\") #Generate sequence"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "torchtext_translation_tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
